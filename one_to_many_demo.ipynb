{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "one_to_many_demo.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq0kkUAc5O5n",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQO2Qp272_ho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "8d65d47c-2942-4c40-d561-84fecf7cb25d"
      },
      "source": [
        "!pip uninstall -y tensorflow numpy && pip install tensorflow-gpu==1.14.0 tf_sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.14.0:\n",
            "  Successfully uninstalled tensorflow-1.14.0\n",
            "Uninstalling numpy-1.16.5:\n",
            "  Successfully uninstalled numpy-1.16.5\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 65kB/s \n",
            "\u001b[?25hCollecting tf_sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/2c/20800032089a9271757921f3adc1f2c7ec2d294ec9fa07b3115fab9d27c2/tf_sentencepiece-0.1.83-py2.py3-none-manylinux1_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.11.2)\n",
            "Collecting numpy<2.0,>=1.14.5 (from tensorflow-gpu==1.14.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/e6/c3fdc53aed9fa19d6ff3abf97dfad768ae3afce1b7431f7500000816bda5/numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
            "\u001b[K     |████████████████████████████████| 20.4MB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.33.6)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.1.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (0.15.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.1)\n",
            "\u001b[31mERROR: stable-baselines 2.2.1 requires tensorflow>=1.5.0, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 requires tensorflow>=1.12.0, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tensorflow-gpu, tf-sentencepiece\n",
            "Successfully installed numpy-1.17.2 tensorflow-gpu-1.14.0 tf-sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRYbl_We431V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5f755702-9233-4bbd-8c54-e12d7b0f9a94"
      },
      "source": [
        "!curl -o one_to_many.zip https://dl.dropboxusercontent.com/s/bssvce8t00zjwxj/one_to_many.zip?dl=0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  115M  100  115M    0     0  38.4M      0  0:00:03  0:00:03 --:--:-- 38.4M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1kWSRVb5F-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q one_to_many.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA7Nd3qo5KM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "fc7d8ae5-6e15-4377-dfeb-baed5fb6a77f"
      },
      "source": [
        "!curl -o mlt.zip https://codeload.github.com/suyash/mlt/zip/master"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 28981    0 28981    0     0   149k      0 --:--:-- --:--:-- --:--:--  150k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg2sGM4N5Ln9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q mlt.zip && mv mlt-master/mlt ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuEV4CUW5ROy",
        "colab_type": "text"
      },
      "source": [
        "## One to Many Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1oy_H3o5MvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tf_sentencepiece as tfs\n",
        "\n",
        "from mlt.evaluation import predict\n",
        "from mlt.layers import Attention, ConditionalNormalization, Gelu, MultiplyConstant, PaddingAndLookaheadMask, PaddingMask, PositionalEncoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXVjFAP55Y9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6216fe02-6d49-4e1b-84db-c258ba07fd63"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UrtqoA85aLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAfwOm9x5baX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_model_file = \"final/sentencepiece/para_crawl/ende_plain_text/models/unigram/8192/a.model\"\n",
        "de_model_file = \"final/sentencepiece/para_crawl/ende_plain_text/models/unigram/8192/b.model\"\n",
        "fr_model_file = \"final/sentencepiece/para_crawl/enfr_plain_text/models/unigram/8192/b.model\"\n",
        "es_model_file = \"final/sentencepiece/para_crawl/enes_plain_text/models/unigram/8192/b.model\"\n",
        "it_model_file = \"final/sentencepiece/para_crawl/enit_plain_text/models/unigram/8192/b.model\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvxp2Swp5d2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_offset = 0\n",
        "fr_offset = 8192\n",
        "de_offset = fr_offset + 8192\n",
        "es_offset = de_offset + 8192\n",
        "it_offset = es_offset + 8192"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbrg8m1U5fIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "70786a53-ce1e-44aa-866b-9d7b6f33ea21"
      },
      "source": [
        "with sess.as_default():\n",
        "    model = tf.keras.experimental.load_from_saved_model(\"final/model114\", custom_objects={\n",
        "        \"MultiplyConstant\": MultiplyConstant,\n",
        "        \"PositionalEncoding\": PositionalEncoding,\n",
        "        \"PaddingMask\": PaddingMask,\n",
        "        \"PaddingAndLookaheadMask\": PaddingAndLookaheadMask,\n",
        "        \"Attention\": Attention,\n",
        "        \"ConditionalNormalization\": ConditionalNormalization,\n",
        "        \"Gelu\": Gelu,\n",
        "    })"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgKgIm625jRP",
        "colab_type": "text"
      },
      "source": [
        "### English to German"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH1XFVga5gZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tfs.encode([\"This is a problem that we have to solve.\"], model_file=en_model_file, add_bos=True, add_eos=True)[0] + en_offset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN0jhGry5odk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "9abaf8fb-707f-408e-dbdd-654e6fa71709"
      },
      "source": [
        "ids, probs = predict(\n",
        "    model=model,\n",
        "    inputs=a,\n",
        "    inpf=tf.constant([1.0]),\n",
        "    tarf=tf.constant([1.0, 0.0, 0.0, 0.0]),\n",
        "    bos_id=de_offset + 1,\n",
        "    eos_id=de_offset + 2,\n",
        "    beam_size=5,\n",
        "    vocab_size=40960,\n",
        "    alpha=1.0,\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/beam_search.py:727: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:2403: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MsOxURV5qH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = tf.cast(tf.not_equal(ids, 0), tf.int32)\n",
        "seq_len = tf.reduce_sum(mask, axis=-1)\n",
        "ids = ids + mask * -de_offset\n",
        "probs = tf.math.exp(probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66oTPUsR5req",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids_, probs_, seq_len_ = sess.run([ids, probs, seq_len])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o883Aol85xNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "40ad7b52-b497-41e8-f89d-fd1fec9b6cf1"
      },
      "source": [
        "[x.decode(\"utf-8\") for x in sess.run(tfs.decode(ids_[0], seq_len_[0], model_file=de_model_file))], probs_[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Dies ist ein Problem, das wir lösen wollen.',\n",
              "  'Das ist ein Problem, das wir lösen wollen.',\n",
              "  'Dies ist ein Problem, das wir lösen können.',\n",
              "  'Das ist ein Problem, das wir lösen können.',\n",
              "  'Das ist ein Problem, das wir lösen haben.'],\n",
              " array([0.5739393 , 0.5204113 , 0.34543523, 0.31465307, 0.2541431 ],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpaALHvr56x0",
        "colab_type": "text"
      },
      "source": [
        "### English to French"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgjkgisG5yV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tfs.encode([\"This is a problem that we have to solve\"], model_file=en_model_file, add_bos=True, add_eos=True)[0] + en_offset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXYizgI06C_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids, probs = predict(\n",
        "    model=model,\n",
        "    inputs=a,\n",
        "    inpf=tf.constant([1.0]),\n",
        "    tarf=tf.constant([0.0, 1.0, 0.0, 0.0]),\n",
        "    bos_id=fr_offset + 1,\n",
        "    eos_id=fr_offset + 2,\n",
        "    beam_size=5,\n",
        "    vocab_size=40960,\n",
        "    alpha=1.0,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en6IYi_M6D5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = tf.cast(tf.not_equal(ids, 0), tf.int32)\n",
        "seq_len = tf.reduce_sum(mask, axis=-1)\n",
        "ids = ids + mask * -fr_offset\n",
        "probs = tf.math.exp(probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmlqX_lw6FI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids_, probs_, seq_len_ = sess.run([ids, probs, seq_len])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1dl-hAE6GLG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "eaeeb08d-d7fd-4fe3-8a7d-2ff91fcbf406"
      },
      "source": [
        "[x.decode(\"utf-8\") for x in sess.run(tfs.decode(ids_[0], seq_len_[0], model_file=fr_model_file))], probs_[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Ce problème est un problème qui nous faut résoudre.',\n",
              "  'Ce problème est un problème qui nous asombant',\n",
              "  'Ce problème est un problème qui nous faut résoudre',\n",
              "  'Ce problème est un problème qui nous asombant.',\n",
              "  \"C'est un problème qui nous a pour résoudre\"],\n",
              " array([0.29952338, 0.2466469 , 0.192374  , 0.17028809, 0.16088726],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt3aez4k6Lzv",
        "colab_type": "text"
      },
      "source": [
        "### English to Spanish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDy9PKeP6HbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tfs.encode([\"This is a problem that we have to solve\"], model_file=en_model_file, add_bos=True, add_eos=True)[0] + en_offset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULV7SQu76S7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids, probs = predict(\n",
        "    model=model,\n",
        "    inputs=a,\n",
        "    inpf=tf.constant([1.0]),\n",
        "    tarf=tf.constant([0.0, 0.0, 1.0, 0.0]),\n",
        "    bos_id=es_offset + 1,\n",
        "    eos_id=es_offset + 2,\n",
        "    beam_size=5,\n",
        "    vocab_size=40960,\n",
        "    alpha=1.0,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBceuuwB6Uaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = tf.cast(tf.not_equal(ids, 0), tf.int32)\n",
        "seq_len = tf.reduce_sum(mask, axis=-1)\n",
        "ids = ids + mask * -es_offset\n",
        "probs = tf.math.exp(probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Waq32kLs6Vyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids_, probs_, seq_len_ = sess.run([ids, probs, seq_len])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXXxpcLk6XBL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b83d028b-b818-4aca-fbe9-3a80cee03b71"
      },
      "source": [
        "[x.decode(\"utf-8\") for x in sess.run(tfs.decode(ids_[0], seq_len_[0], model_file=es_model_file))], probs_[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Este es un problema que necesitamos resolver',\n",
              "  'Este es un problema que nosotros necesitamos resolver',\n",
              "  'Este es un problema que tenemos que vender',\n",
              "  'Es un problema que necesitamos resolver',\n",
              "  'Este es un problema que tenemos para solucionar'],\n",
              " array([0.63790417, 0.33507025, 0.2521149 , 0.2309758 , 0.20429674],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgWiupN-6b-N",
        "colab_type": "text"
      },
      "source": [
        "### English to Italian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWkLJP9Y6YX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tfs.encode([\"This is a problem that we have to solve\"], model_file=en_model_file, add_bos=True, add_eos=True)[0] + en_offset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k33TP3wZ6e7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids, probs = predict(\n",
        "    model=model,\n",
        "    inputs=a,\n",
        "    inpf=tf.constant([1.0]),\n",
        "    tarf=tf.constant([0.0, 0.0, 0.0, 1.0]),\n",
        "    bos_id=it_offset + 1,\n",
        "    eos_id=it_offset + 2,\n",
        "    beam_size=5,\n",
        "    vocab_size=40960,\n",
        "    alpha=1.0,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2eNZu0K6f9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = tf.cast(tf.not_equal(ids, 0), tf.int32)\n",
        "seq_len = tf.reduce_sum(mask, axis=-1)\n",
        "ids = ids + mask * -it_offset\n",
        "probs = tf.math.exp(probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YeRSjk36hL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids_, probs_, seq_len_ = sess.run([ids, probs, seq_len])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Armf6bX6icz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9ba96879-e3f4-47a1-f47b-9316f19e3f45"
      },
      "source": [
        "[x.decode(\"utf-8\") for x in sess.run(tfs.decode(ids_[0], seq_len_[0], model_file=it_model_file))], probs_[0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Questo è un problema che abbiamo bisogno di risolvere',\n",
              "  'Questo è un problema che vogliamo',\n",
              "  'Questo è un problema che abbiamo dovuto risolvere',\n",
              "  'Questo è un problema che vogliamo risolvere',\n",
              "  'Questo è un problema che dobbiamo risolvere'],\n",
              " array([0.5477947 , 0.5022847 , 0.24332887, 0.22610326, 0.20580557],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WKbUxHh6jlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}